# twinny

### [Install the vscode extension](https://marketplace.visualstudio.com/items?itemName=rjmacarthy.twinny#review-details)

**twinny** is a locally hosted AI code completion plugin for vscode, designed to work seamlessly with [ollama](https://github.com/jmorganca/ollama).

![twinny](https://github.com/rjmacarthy/twinny/assets/5537428/95a1d8d5-f2fb-47b3-b246-23ff822464c3)

## Features ðŸ¤–

- Auto code completion
- Fast and accurate
- Multiple language support
- Easy to install
- Free
- Private
- Configurable endpoint and port for Ollama API

## ðŸš€ Getting Started

### Easy Installation

**twinny** and **ollama** are designed to work together. When installing the **twinny** extension in Visual Studio Code, it will automatically prompt and guide you through the installation of **ollama**, ensuring a seamless setup process.

Install the verified extension at [this link](https://marketplace.visualstudio.com/items?itemName=rjmacarthy.twinny)

When the extension is running and the Ollama server is running you will see a `ðŸ¤–` icon at the bottom of your code editor.

Enjoy enhanced code completions with **twinny**! ðŸŽ‰

### Development and contributions

1. Clone this repository:

```
git clone https://github.com/rjmacarthy/twinny.git
```

2. Navigate to the cloned directory:

```
cd twinny
```

3. Install the necessary dependencies:

```
npm install
```

4. Start the plugin in development mode by pressing `F5` within Visual Studio Code.

Contributions are welcome please open an issue describing your changes and open a pull request when ready.

This project is under MIT licence, please read the [LICENSE](https://github.com/rjmacarthy/twinny/blob/master/LICENSE) file for more information.
